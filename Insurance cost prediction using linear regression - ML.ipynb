{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5234212b",
   "metadata": {},
   "source": [
    "## Linear Regression with PyTorch - Machine Learning with Python\n",
    "\n",
    "### Insurance cost prediction using linear regression\n",
    "\n",
    "\n",
    "In this assignment we're going to use information like a person's age, sex, BMI, no. of children and smoking habit to predict the price of yearly medical bills. This kind of model is useful for insurance companies to determine the yearly insurance premium for a person. The dataset for this problem is taken from [Kaggle](https://www.kaggle.com/mirichoi0218/insurance).\n",
    "\n",
    "\n",
    "We will create a model with the following steps:\n",
    "1. Download and explore the dataset\n",
    "2. Prepare the dataset for training\n",
    "3. Create a linear regression model\n",
    "4. Train the model to fit the data\n",
    "5. Make predictions using the trained model\n",
    "\n",
    "\n",
    "This assignment builds upon the concepts from the first 2 lessons. It will help to review these Jupyter notebooks:\n",
    "- PyTorch basics: https://jovian.ai/aakashns/01-pytorch-basics\n",
    "- Linear Regression: https://jovian.ai/aakashns/02-linear-regression\n",
    "- Logistic Regression: https://jovian.ai/aakashns/03-logistic-regression\n",
    "- Linear regression (minimal): https://jovian.ai/aakashns/housing-linear-minimal\n",
    "- Logistic regression (minimal): https://jovian.ai/aakashns/mnist-logistic-minimal\n",
    "\n",
    "As you go through this notebook, you will find a **???** in certain places. Your job is to replace the **???** with appropriate code or values, to ensure that the notebook runs properly end-to-end . In some cases, you'll be required to choose some hyperparameters (learning rate, batch size etc.). Try to experiment with the hypeparameters to get the lowest loss\n",
    "- Insurance Model using Pytorch: https://www.kaggle.com/code/sanath123/insurance-model-using-pytorch/notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef4cc52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\lib\\site-packages (1.7.1+cpu)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\anaconda3\\lib\\site-packages (0.8.2+cpu)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\user\\anaconda3\\lib\\site-packages (0.7.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (4.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (1.21.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (9.0.1)\n"
     ]
    }
   ],
   "source": [
    "# Uncomment and run the appropriate command for your operating system, if required\n",
    "\n",
    "# Linux / Binder\n",
    "# !pip install torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# !pip install torch==1.7.1+cpu torchvision==0.8.2+cpu -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "# Windows\n",
    "#!pip install torch==1.9.1+cpu torchvision==0.10.1+cpu torchaudio==0.9.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "#!pip install torch==1.7.1+cpu torchvision==0.8.2+cpu -f https://download.pytorch.org/whl/torch_stable.html\n",
    "### the line below works for Windows - Thank God!\n",
    "#!pip install torch torchvision torchaudio\n",
    "\n",
    "# MacOS\n",
    "# !pip install numpy matplotlib pandas torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780a9fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dc2e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dce39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "faacaa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b4faf3",
   "metadata": {},
   "source": [
    "## Step 1: Download and explore the data\n",
    "\n",
    "Let us begin by downloading the data. We'll use the `download_url` function from PyTorch to get the data as a CSV (comma-separated values) file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f467859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: .\\insurance.csv\n"
     ]
    }
   ],
   "source": [
    "DATASET_URL = \"https://gist.githubusercontent.com/BirajCoder/5f068dfe759c1ea6bdfce9535acdb72d/raw/c84d84e3c80f93be67f6c069cbdc0195ec36acbd/insurance.csv\"\n",
    "DATA_FILENAME = \"insurance.csv\"\n",
    "download_url(DATASET_URL, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8de4aad",
   "metadata": {},
   "source": [
    "To load the dataset into memory, we'll use the `read_csv` function from the `pandas` library. The data will be loaded as a Pandas dataframe. See this short tutorial to learn more: https://data36.com/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "701dbcd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_raw = pd.read_csv(DATA_FILENAME)\n",
    "dataframe_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e374d0f",
   "metadata": {},
   "source": [
    "We're going to do a slight customization of the data, so that you every participant receives a slightly different version of the dataset. Fill in your name below as a string (enter at least 5 characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "713140ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_name = 'Achan' # at least 5 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a607a5ab",
   "metadata": {},
   "source": [
    "The `customize_dataset` function will customize the dataset slightly using your name as a source of random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "703cd82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full set of data being used instead of .95, and inlcude 'region' variable\n",
    "def customize_dataset(dataframe_raw, rand_str):\n",
    "    dataframe = dataframe_raw.copy(deep=True)\n",
    "    # drop some rows s.t. use 0.95\n",
    "    dataframe = dataframe.sample(int(1.00*len(dataframe)), random_state=int(ord(rand_str[0])))\n",
    "    # scale input\n",
    "    dataframe.bmi = dataframe.bmi * ord(rand_str[1])/100.\n",
    "    # scale target\n",
    "    dataframe.charges = dataframe.charges * ord(rand_str[2])/100.\n",
    "    # drop column\n",
    "    #if ord(rand_str[3]) % 2 == 1:\n",
    "        #dataframe = dataframe.drop(['region'], axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "5cf1ed1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>55</td>\n",
       "      <td>female</td>\n",
       "      <td>32.44725</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>12759.377540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>64</td>\n",
       "      <td>male</td>\n",
       "      <td>37.52595</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>14778.957388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>55</td>\n",
       "      <td>male</td>\n",
       "      <td>37.33785</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>31266.123772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>44</td>\n",
       "      <td>male</td>\n",
       "      <td>21.91365</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>8634.637076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>33</td>\n",
       "      <td>female</td>\n",
       "      <td>24.06690</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4352.501816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex       bmi  children smoker     region       charges\n",
       "27     55  female  32.44725         2     no  northwest  12759.377540\n",
       "752    64    male  37.52595         0     no  northwest  14778.957388\n",
       "1258   55    male  37.33785         3     no  northwest  31266.123772\n",
       "384    44    male  21.91365         2     no  northeast   8634.637076\n",
       "406    33  female  24.06690         0     no  southeast   4352.501816"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = customize_dataset(dataframe_raw, your_name)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "bb058529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1338\n"
     ]
    }
   ],
   "source": [
    "#How many rows does the dataset have?\n",
    "num_rows = dataframe.shape[0]\n",
    "print(num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "5d0d508b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "#How many columns does the dataset have?\n",
    "num_cols = dataframe.shape[1]\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "fcf8ae24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges']\n"
     ]
    }
   ],
   "source": [
    "#1271 rows x 6 columns\n",
    "# What are the columns of the dataset have?\n",
    "input_cols = ['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges']\n",
    "print(input_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "eef25a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'smoker', 'region']\n"
     ]
    }
   ],
   "source": [
    "#Which of the input columns are non-numeric or categorial variables ?\n",
    "categorical_cols = ['sex', 'smoker', 'region']\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "119cfd90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['charges']"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What are the column titles of output/target variable(s)?\n",
    "output_cols=['charges']\n",
    "output_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b937548",
   "metadata": {},
   "source": [
    "**Q: (Optional) What is the minimum, maximum and average value of the `charges` column? Can you show the distribution of values in a graph?**\n",
    "Use this data visualization cheatsheet for referece: https://jovian.ai/aakashns/dataviz-cheatsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "3a9068cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.207025</td>\n",
       "      <td>30.356763</td>\n",
       "      <td>1.094918</td>\n",
       "      <td>13801.239156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.049960</td>\n",
       "      <td>6.037205</td>\n",
       "      <td>1.205493</td>\n",
       "      <td>12594.411686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>15.800400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1166.748856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>26.033288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4929.898636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>30.096000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9757.314320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>34.346812</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>17305.509016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>52.598700</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>66321.245130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          bmi     children       charges\n",
       "count  1338.000000  1338.000000  1338.000000   1338.000000\n",
       "mean     39.207025    30.356763     1.094918  13801.239156\n",
       "std      14.049960     6.037205     1.205493  12594.411686\n",
       "min      18.000000    15.800400     0.000000   1166.748856\n",
       "25%      27.000000    26.033288     0.000000   4929.898636\n",
       "50%      39.000000    30.096000     1.000000   9757.314320\n",
       "75%      51.000000    34.346812     2.000000  17305.509016\n",
       "max      64.000000    52.598700     5.000000  66321.245130"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.describe()\n",
    "#dataframe[['charges']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cde95a1",
   "metadata": {},
   "source": [
    "## Step 2: Prepare the dataset for training\n",
    "\n",
    "We need to convert the data from the Pandas dataframe into a PyTorch tensors for training. To do this, the first step is to convert it numpy arrays. If you've filled out `input_cols`, `categorial_cols` and `output_cols` correctly, this following function will perform the conversion to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "afcff26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_arrays(dataframe):\n",
    "    # Make a copy of the original dataframe\n",
    "    dataframe1 = dataframe.copy(deep=True)\n",
    "    # Convert non-numeric categorical columns to numbers\n",
    "    for col in categorical_cols:\n",
    "        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n",
    "    # Extract input & outupts as numpy arrays\n",
    "    inputs_array = dataframe1[input_cols].to_numpy()\n",
    "    targets_array = dataframe1[output_cols].to_numpy()\n",
    "    return inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d273bf",
   "metadata": {},
   "source": [
    "Read through the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html) to understand how we're converting categorical variables into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "8df0f705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5.50000000e+01, 0.00000000e+00, 3.24472500e+01, ...,\n",
       "         0.00000000e+00, 1.00000000e+00, 1.27593775e+04],\n",
       "        [6.40000000e+01, 1.00000000e+00, 3.75259500e+01, ...,\n",
       "         0.00000000e+00, 1.00000000e+00, 1.47789574e+04],\n",
       "        [5.50000000e+01, 1.00000000e+00, 3.73378500e+01, ...,\n",
       "         0.00000000e+00, 1.00000000e+00, 3.12661238e+04],\n",
       "        ...,\n",
       "        [1.90000000e+01, 1.00000000e+00, 2.74230000e+01, ...,\n",
       "         1.00000000e+00, 3.00000000e+00, 1.69497598e+04],\n",
       "        [5.80000000e+01, 0.00000000e+00, 2.68983000e+01, ...,\n",
       "         0.00000000e+00, 1.00000000e+00, 1.27118142e+04],\n",
       "        [2.90000000e+01, 0.00000000e+00, 2.76606000e+01, ...,\n",
       "         1.00000000e+00, 2.00000000e+00, 1.98720908e+04]]),\n",
       " array([[12759.37754 ],\n",
       "        [14778.957388],\n",
       "        [31266.123772],\n",
       "        ...,\n",
       "        [16949.75984 ],\n",
       "        [12711.814232],\n",
       "        [19872.090784]]))"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_array, targets_array = dataframe_to_arrays(dataframe)\n",
    "inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "70efd37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the numpy arrays `inputs_array` and `targets_array` \n",
    "#into PyTorch tensors. Make sure that the data type is `torch.float32`.**\n",
    "inputs = inputs_array\n",
    "targets = targets_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "ae730255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), dtype('float64'))"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype, targets.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5bf15f",
   "metadata": {},
   "source": [
    "Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a `TensorDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "47d11c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_x = torch.Tensor(inputs) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(targets)\n",
    "\n",
    "dataset = TensorDataset(tensor_x,tensor_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "378b0ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if Make sure that the data type is `torch.float32`.**\n",
    "tensor_x.dtype, tensor_y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1796cd",
   "metadata": {},
   "source": [
    "Pick a number between `0.1` and `0.2` to determine the fraction of data that will be used for creating the validation set. Then use `random_split` to create training & validation datasets.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab394bf",
   "metadata": {},
   "source": [
    "val_percent = 0.2 # between 0.1 and 0.2\n",
    "val_size = int(num_rows * val_percent)\n",
    "train_size = num_rows - val_size\n",
    "\n",
    "# Use the random_split function to split dataset into 2 parts of the desired length\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size,val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "096f074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_percent = 0.2 # between 0.1 and 0.2\n",
    "val_size = int(num_rows * val_percent)\n",
    "train_size = num_rows - val_size\n",
    "\n",
    "train_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "# train_ds, val_ds = ??? # Use the random_split function to split dataset into 2 parts of the desired length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "c6895fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick a batch size for the data loader\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "b419e8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdda695",
   "metadata": {},
   "source": [
    "Let's look at a batch of data to verify everything is working fine so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "2bbafe07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: tensor([[1.9000e+01, 1.0000e+00, 3.0096e+01, 0.0000e+00, 0.0000e+00, 3.0000e+00,\n",
      "         1.3066e+03],\n",
      "        [6.0000e+01, 0.0000e+00, 2.5582e+01, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         3.0080e+04],\n",
      "        [2.2000e+01, 1.0000e+00, 3.1037e+01, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         2.7490e+03],\n",
      "        [3.7000e+01, 0.0000e+00, 3.8006e+01, 0.0000e+00, 1.0000e+00, 2.0000e+00,\n",
      "         4.2036e+04],\n",
      "        [5.1000e+01, 0.0000e+00, 3.7679e+01, 0.0000e+00, 1.0000e+00, 2.0000e+00,\n",
      "         4.6176e+04],\n",
      "        [5.0000e+01, 1.0000e+00, 2.5047e+01, 0.0000e+00, 0.0000e+00, 2.0000e+00,\n",
      "         8.7804e+03],\n",
      "        [3.1000e+01, 1.0000e+00, 3.0754e+01, 3.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         5.6420e+03],\n",
      "        [4.5000e+01, 0.0000e+00, 2.5443e+01, 3.0000e+00, 0.0000e+00, 3.0000e+00,\n",
      "         9.4659e+03],\n",
      "        [3.1000e+01, 1.0000e+00, 3.9095e+01, 1.0000e+00, 0.0000e+00, 2.0000e+00,\n",
      "         4.0308e+03],\n",
      "        [2.4000e+01, 0.0000e+00, 2.7443e+01, 0.0000e+00, 0.0000e+00, 2.0000e+00,\n",
      "         2.5632e+03],\n",
      "        [3.2000e+01, 1.0000e+00, 4.6065e+01, 2.0000e+00, 0.0000e+00, 2.0000e+00,\n",
      "         4.8738e+03],\n",
      "        [3.6000e+01, 0.0000e+00, 1.9656e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.6764e+03],\n",
      "        [5.3000e+01, 1.0000e+00, 3.5739e+01, 1.0000e+00, 0.0000e+00, 3.0000e+00,\n",
      "         1.0489e+04],\n",
      "        [2.4000e+01, 1.0000e+00, 2.6522e+01, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.3114e+04],\n",
      "        [5.8000e+01, 0.0000e+00, 2.6898e+01, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.2712e+04],\n",
      "        [5.7000e+01, 1.0000e+00, 2.7661e+01, 1.0000e+00, 0.0000e+00, 2.0000e+00,\n",
      "         1.2016e+04],\n",
      "        [5.3000e+01, 0.0000e+00, 3.9204e+01, 1.0000e+00, 0.0000e+00, 2.0000e+00,\n",
      "         1.1003e+04],\n",
      "        [3.9000e+01, 1.0000e+00, 4.4976e+01, 2.0000e+00, 0.0000e+00, 2.0000e+00,\n",
      "         6.6105e+03],\n",
      "        [3.5000e+01, 0.0000e+00, 3.3764e+01, 3.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         4.1583e+04],\n",
      "        [3.1000e+01, 0.0000e+00, 2.5542e+01, 2.0000e+00, 0.0000e+00, 3.0000e+00,\n",
      "         5.1321e+03],\n",
      "        [3.9000e+01, 1.0000e+00, 2.9626e+01, 1.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         2.3361e+04],\n",
      "        [2.5000e+01, 0.0000e+00, 2.2290e+01, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         3.7379e+03],\n",
      "        [5.8000e+01, 0.0000e+00, 3.1507e+01, 2.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.4152e+04],\n",
      "        [5.5000e+01, 1.0000e+00, 2.7369e+01, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.1018e+04],\n",
      "        [1.9000e+01, 0.0000e+00, 2.8611e+01, 0.0000e+00, 0.0000e+00, 3.0000e+00,\n",
      "         1.8129e+03],\n",
      "        [5.3000e+01, 1.0000e+00, 3.3764e+01, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         4.4985e+04],\n",
      "        [3.7000e+01, 0.0000e+00, 2.7463e+01, 3.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         7.5728e+03],\n",
      "        [5.4000e+01, 0.0000e+00, 3.0928e+01, 0.0000e+00, 0.0000e+00, 2.0000e+00,\n",
      "         1.0752e+04],\n",
      "        [2.3000e+01, 0.0000e+00, 4.2322e+01, 1.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         4.2540e+04],\n",
      "        [1.9000e+01, 1.0000e+00, 2.9948e+01, 0.0000e+00, 1.0000e+00, 2.0000e+00,\n",
      "         3.3850e+04],\n",
      "        [3.2000e+01, 1.0000e+00, 3.6962e+01, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.8543e+03],\n",
      "        [2.1000e+01, 1.0000e+00, 2.8685e+01, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.9826e+03]])\n",
      "targets: tensor([[ 1306.5509],\n",
      "        [30080.0625],\n",
      "        [ 2748.9993],\n",
      "        [42035.7812],\n",
      "        [46176.4219],\n",
      "        [ 8780.3740],\n",
      "        [ 5642.0244],\n",
      "        [ 9465.8701],\n",
      "        [ 4030.7634],\n",
      "        [ 2563.2036],\n",
      "        [ 4873.8442],\n",
      "        [ 5676.3682],\n",
      "        [10489.2803],\n",
      "        [13114.2822],\n",
      "        [12711.8145],\n",
      "        [12016.3926],\n",
      "        [11002.8994],\n",
      "        [ 6610.5215],\n",
      "        [41582.7617],\n",
      "        [ 5132.0933],\n",
      "        [23360.5254],\n",
      "        [ 3737.9377],\n",
      "        [14151.6631],\n",
      "        [11018.2812],\n",
      "        [ 1812.9425],\n",
      "        [44984.5938],\n",
      "        [ 7572.7656],\n",
      "        [10752.4893],\n",
      "        [42540.3672],\n",
      "        [33850.2734],\n",
      "        [ 4854.3120],\n",
      "        [ 1982.6125]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_loader:\n",
    "    print(\"inputs:\", xb)\n",
    "    print(\"targets:\", yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bf7dc3",
   "metadata": {},
   "source": [
    "## Step 3: Create a Linear Regression Model\n",
    "\n",
    "Our model itself is a fairly straightforward linear regression (we'll build more complex models in the next assignment). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "8495a1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(input_cols)\n",
    "output_size = len(output_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "4322ed09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "51ffb965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e199a5c",
   "metadata": {},
   "source": [
    "**Q : Complete the class definition below by filling out the constructor (`__init__`), `forward`, `training_step` and `validation_step` methods.**\n",
    "\n",
    "Hint: Think carefully about picking a good loss fuction (it's not cross entropy). Maybe try 2-3 of them and see which one works best. See https://pytorch.org/docs/stable/nn.functional.html#loss-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "f50ebf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsuranceModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 =  nn.Linear(input_size,40) \n",
    "        self.linear2 =  nn.Linear(40,output_size) \n",
    "        \n",
    "        # fill this (hint: use input_size & output_size defined above)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        x1 = F.relu(self.linear1(xb))\n",
    "        x2 = F.relu(self.linear2(x1))\n",
    "        out = x2                      # fill this\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        inputs, targets = batch \n",
    "        # Generate predictions\n",
    "        out = self(inputs)          \n",
    "        # Calcuate loss\n",
    "        loss = F.mse_loss(out, targets)                          # fill this\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        # Generate predictions\n",
    "        out = self(inputs)\n",
    "        # Calculate loss\n",
    "        loss = F.mse_loss(out, targets)                           # fill this    \n",
    "        return {'val_loss': loss.detach()}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        return {'val_loss': epoch_loss.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result, num_epochs):\n",
    "        # Print result every 20th epoch\n",
    "        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n",
    "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032f3418",
   "metadata": {},
   "source": [
    "Let us create a model using the `InsuranceModel` class. You may need to come back later and re-run the next cell to reinitialize the model, in case the loss becomes `nan` or `infinity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "92d5d59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InsuranceModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3272a274",
   "metadata": {},
   "source": [
    "Let's check out the weights and biases of the model using `model.parameters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "0d953c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.2350, -0.1937, -0.2645, -0.0269,  0.0139, -0.1765, -0.0352],\n",
       "         [ 0.1605,  0.0977,  0.0167, -0.3663, -0.2933,  0.2976,  0.3662],\n",
       "         [-0.2715,  0.1109,  0.0376, -0.0430,  0.0293,  0.0323, -0.3228],\n",
       "         [ 0.3725,  0.1816,  0.2741, -0.3072,  0.2767, -0.3741,  0.2467],\n",
       "         [ 0.1316, -0.2969, -0.1938, -0.3118,  0.2111,  0.3022,  0.3609],\n",
       "         [-0.2005,  0.0108,  0.1126,  0.0312,  0.0603, -0.2224,  0.1240],\n",
       "         [ 0.0186,  0.1288,  0.0685, -0.3030,  0.1368,  0.1665,  0.3240],\n",
       "         [ 0.2916, -0.0891, -0.1479,  0.2005,  0.1523, -0.3445, -0.2792],\n",
       "         [ 0.1254,  0.0307,  0.0340,  0.0461, -0.2739, -0.2991, -0.0582],\n",
       "         [ 0.0286,  0.1906, -0.0699, -0.2248, -0.0842,  0.3518,  0.3644],\n",
       "         [-0.2709, -0.3195,  0.3215, -0.3466, -0.1025,  0.3241, -0.0589],\n",
       "         [ 0.1220,  0.0774,  0.1784,  0.3565, -0.1950,  0.1857,  0.0093],\n",
       "         [-0.2941, -0.0550,  0.1528,  0.0108,  0.1393, -0.0102, -0.2319],\n",
       "         [ 0.0466,  0.3422,  0.1180, -0.2243,  0.0615, -0.3054,  0.3313],\n",
       "         [ 0.3394,  0.1530,  0.2407,  0.2614, -0.1370,  0.2986, -0.0134],\n",
       "         [-0.1209,  0.0954, -0.2364,  0.1589, -0.0655, -0.2848,  0.2141],\n",
       "         [ 0.1874, -0.2720, -0.3597,  0.0622,  0.1146,  0.1053,  0.3421],\n",
       "         [ 0.1862,  0.2950, -0.2722, -0.2464, -0.3120,  0.1804, -0.3103],\n",
       "         [-0.0883,  0.0565,  0.0726, -0.2984, -0.0661,  0.1961, -0.0033],\n",
       "         [-0.1796, -0.0808, -0.1772,  0.3637, -0.3565,  0.3104,  0.1555],\n",
       "         [ 0.2650, -0.0490, -0.0972,  0.2463,  0.2385,  0.0398, -0.3044],\n",
       "         [-0.1277, -0.1741,  0.1002, -0.2867,  0.3665, -0.2318,  0.1791],\n",
       "         [-0.0861, -0.3671, -0.3264,  0.0028,  0.2281, -0.0072, -0.1907],\n",
       "         [-0.3556,  0.1076, -0.3259,  0.0943, -0.1802,  0.1452, -0.1683],\n",
       "         [-0.3516, -0.0552, -0.0838,  0.0689, -0.3293, -0.1505,  0.0118],\n",
       "         [-0.1166, -0.1438, -0.2234, -0.0665,  0.3190,  0.0518, -0.0145],\n",
       "         [-0.2869,  0.1479, -0.0860, -0.0604,  0.2487,  0.0785, -0.0051],\n",
       "         [-0.2459, -0.2101,  0.2533, -0.2759,  0.1649,  0.1750,  0.2380],\n",
       "         [-0.1400, -0.0973, -0.3214,  0.3174,  0.2643,  0.1958,  0.1459],\n",
       "         [-0.0836, -0.1928, -0.1762,  0.3129,  0.0552,  0.0339,  0.2244],\n",
       "         [-0.2081, -0.3215,  0.3635, -0.2901, -0.3327,  0.2354, -0.2772],\n",
       "         [-0.1749,  0.2340,  0.2133,  0.0074,  0.3276, -0.0104, -0.1648],\n",
       "         [ 0.2949,  0.2852,  0.0935, -0.3178, -0.1597,  0.2200, -0.2638],\n",
       "         [ 0.3040, -0.1558,  0.2941,  0.1476,  0.1876,  0.2530, -0.1059],\n",
       "         [ 0.0190,  0.1181, -0.1514, -0.1929,  0.2441, -0.1467, -0.0711],\n",
       "         [ 0.0069, -0.0402,  0.1790,  0.0576,  0.3176,  0.1690,  0.1308],\n",
       "         [-0.1658,  0.1040, -0.3200,  0.0377, -0.0994, -0.3306,  0.3098],\n",
       "         [ 0.0138,  0.1131,  0.2482, -0.0323,  0.0944,  0.0225,  0.0824],\n",
       "         [ 0.0308, -0.3481,  0.1841, -0.1499, -0.2425,  0.1925,  0.0048],\n",
       "         [ 0.0200, -0.3739,  0.2653, -0.3667,  0.0100, -0.1947, -0.1121]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-1.0658e-01, -1.7306e-01,  3.1071e-01, -2.5285e-01,  1.8151e-01,\n",
       "          1.8743e-01,  9.0303e-02, -1.1495e-01,  5.9427e-02, -3.6043e-01,\n",
       "          9.9341e-02,  3.5696e-01,  2.9239e-01,  1.8212e-01,  1.9225e-01,\n",
       "          3.0335e-01, -1.9370e-01,  1.7554e-01,  3.4782e-01, -1.9809e-01,\n",
       "          1.8530e-01, -1.1310e-02, -1.9929e-01, -1.1659e-01,  9.0060e-02,\n",
       "          1.1796e-01,  1.9755e-01, -9.8444e-02,  1.7081e-01, -8.9576e-03,\n",
       "         -2.7501e-01, -8.0114e-02,  1.5093e-01,  1.6072e-01, -3.2223e-01,\n",
       "         -2.1665e-01,  2.8774e-04,  7.2621e-03, -2.3255e-01, -3.7575e-01],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.1463, -0.0487, -0.0833, -0.1048,  0.0277,  0.0744, -0.0319, -0.0112,\n",
       "          -0.1369, -0.0243,  0.0138, -0.1144, -0.0655,  0.1324,  0.0743,  0.0236,\n",
       "           0.0419,  0.0448,  0.0704, -0.1201, -0.1065,  0.1032, -0.1238,  0.0824,\n",
       "           0.1524, -0.0212,  0.1413, -0.0025,  0.0484,  0.1063, -0.0879,  0.0338,\n",
       "          -0.0399, -0.1246,  0.0106,  0.1495, -0.1199, -0.1252,  0.0223, -0.0929]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0148], requires_grad=True)]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2136df3c",
   "metadata": {},
   "source": [
    "**Step 4**: Train the model to fit the data\n",
    "To train our model, we'll use the same fit function explained in the lecture. That's the benefit of defining a generic training loop - you can use it for any problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "79bc38c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result, epochs)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238400c9",
   "metadata": {},
   "source": [
    "Q: Use the evaluate function to calculate the loss on the validation set before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "91cb4d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': 297221120.0}\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(model, val_loader) # Use the the evaluate function\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "15b581ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': 336659008.0}\n"
     ]
    }
   ],
   "source": [
    "# Extra: Just check the train_loader\n",
    "result_t = evaluate(model, train_loader) # Use the the evaluate function\n",
    "print(result_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d920695f",
   "metadata": {},
   "source": [
    "We are now ready to train the model. You may need to run the training loop many times, for different number of epochs and with different learning rates, to get a good result. Also, if your loss becomes too large (or nan), you may have to re-initialize the model by running the cell model = InsuranceModel(). Experiment with this for a while, and try to get to as low a loss as possible.\n",
    "\n",
    "**Q: Train the model 4-5 times with different learning rates & for different number of epochs.**\n",
    "\n",
    "Hint: Vary learning rates by orders of 10 (e.g. 1e-2, 1e-3, 1e-4, 1e-5, 1e-6) to figure out what works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "555e28c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], val_loss: 310975808.0000\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "lr = 0.01\n",
    "history1 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "0771444d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 310975808.0000\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "lr = .001\n",
    "history2 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "19e20bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 310975808.0000\n",
      "Epoch [30], val_loss: 310975808.0000\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "lr = .00001\n",
    "history3 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "3c46b679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 310975808.0000\n",
      "Epoch [40], val_loss: 310975808.0000\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "lr = .000001\n",
    "history4 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "7c307f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 310975808.0000\n",
      "Epoch [40], val_loss: 310975808.0000\n",
      "Epoch [60], val_loss: 310975808.0000\n",
      "Epoch [80], val_loss: 310975808.0000\n",
      "Epoch [100], val_loss: 310975808.0000\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "lr = .00001\n",
    "history5 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc492ab",
   "metadata": {},
   "source": [
    "Q: What is the final validation loss of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "683f73d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_loss = 325285792.0000 for split =.1, and 336885312.0000 for split =.2\n",
    "val_loss = 323426336.0000 # 336885312.0000 # 428244992.0000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c525e2",
   "metadata": {},
   "source": [
    "### Step 5: Make predictions using the trained model\n",
    "Q: Complete the following function definition to make predictions on a single input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "c480d445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(input, target, model):\n",
    "    inputs = input.unsqueeze(0)\n",
    "    predictions = model.forward(inputs)                # fill this\n",
    "    prediction = predictions[0].detach()\n",
    "    print(\"Input:\", input)\n",
    "    print(\"Target:\", target)\n",
    "    print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "236778e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([4.2000e+01, 1.0000e+00, 2.4394e+01, 0.0000e+00, 1.0000e+00, 2.0000e+00,\n",
      "        2.0296e+04])\n",
      "Target: tensor([20296.1641])\n",
      "Prediction: tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[0]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "b89c4855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([4.2000e+01, 0.0000e+00, 2.4735e+01, 2.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "        8.3377e+03])\n",
      "Target: tensor([8337.7432])\n",
      "Prediction: tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[10]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "c33dda2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([3.2000e+01, 0.0000e+00, 4.0689e+01, 0.0000e+00, 0.0000e+00, 3.0000e+00,\n",
      "        4.1494e+03])\n",
      "Target: tensor([4149.4346])\n",
      "Prediction: tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[23]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "a9ff95d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([5.5000e+01, 0.0000e+00, 2.9839e+01, 2.0000e+00, 0.0000e+00, 2.0000e+00,\n",
      "        1.2357e+04])\n",
      "Target: tensor([12357.2480])\n",
      "Prediction: tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[100]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d308b9f4",
   "metadata": {},
   "source": [
    "### (Optional) Step 6: Try another dataset & blog about it\n",
    "While this last step is optional for the submission of your assignment, we highly recommend that you do it. Try to clean up & replicate this notebook (or this one, or this one ) for a different linear regression or logistic regression problem. This will help solidify your understanding, and give you a chance to differentiate the generic patters in machine learning from problem-specific details.\n",
    "\n",
    "Here are some sources to find good datasets:\n",
    "\n",
    "- https://lionbridge.ai/datasets/10-open-datasets-for-linear-regression/\n",
    "- https://www.kaggle.com/rtatman/datasets-for-regression-analysis\n",
    "- https://archive.ics.uci.edu/ml/datasets.php?format=&task=reg&att=&area=&numAtt=&numIns=&type=&sort=nameUp&view=table\n",
    "- https://people.sc.fsu.edu/~jburkardt/datasets/regression/regression.html\n",
    "- https://archive.ics.uci.edu/ml/datasets/wine+quality\n",
    "- https://pytorch.org/docs/stable/torchvision/datasets.html\n",
    "\n",
    "We also recommend that you write a blog about your approach to the problem. Here is a suggested structure for your post (feel free to experiment with it):\n",
    "\n",
    "- Interesting title & subtitle\n",
    "- Overview of what the blog covers (which dataset, linear regression or logistic regression, intro to PyTorch)\n",
    "- Downloading & exploring the data\n",
    "- Preparing the data for training\n",
    "- Creating a model using PyTorch\n",
    "- Training the model to fit the data\n",
    "- Your thoughts on how to experiment with different hyperparmeters to reduce loss\n",
    "- Making predictions using the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aa1f4b",
   "metadata": {},
   "source": [
    "Ref. source: https://www.kaggle.com/code/sanath123/insurance-model-using-pytorch/notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
